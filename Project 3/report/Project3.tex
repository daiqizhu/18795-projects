\documentclass{article}

\usepackage{amsmath,amsfonts,amsthm,amssymb}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{lastpage}
\usepackage{graphicx}
\usepackage{supertabular}
\usepackage{multirow}
\usepackage{ifthen}
\usepackage{enumerate}
\usepackage{subcaption}
\usepackage[hidelinks]{hyperref}
\usepackage{soul}

% In case you need to adjust margins:
\topmargin=-0.5in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

% Homework Specific Information
\newcommand{\hmwkTitle}{Project Report 3}
\newcommand{\hmwkDueDate}{April 9th, 2014}
\newcommand{\hmwkClass}{42-731}
\newcommand{\hmwkAuthor}{Alex Sun Yoo, Michael Nye, Ozan Iskilibli}
\newcommand{\hmwkEmail}{ayoo, mnye, oiskilib}
\newcommand{\hmwkCollaborators}{}
\newcommand{\bigspace}{\vspace{.25in}}

% Tools for formatting questions
\newcommand{\question}[1] {\vspace{.25in} \hrule\vspace{0.5em}
\noindent{\bf #1} \vspace{0.5em}
\hrule \vspace{.10in}}
\renewcommand{\part}[1] {\vspace{.10in} {\bf (#1)}}

% Setup the header and footer
\pagestyle{fancyplain}
\lhead{\fancyplain{}{\hmwkAuthor \\ \hmwkEmail}}
\chead{\fancyplain{}{\textbf{\hmwkTitle}}}
\rhead{\fancyplain{}{\hmwkClass \\ Due:\ \hmwkDueDate}}
\lfoot{}
\cfoot{}
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}}
\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

% Format paragraphs to have spacing instead of indents
\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}

% This is used to trace down (pin point) problems
% in latexing a document:
%\tracingall

\renewcommand{\arraystretch}{1.5}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\thispagestyle{plain}
\begin{center}
{\Large \hmwkClass\ \hmwkTitle} \\
\hmwkAuthor \\
\hmwkEmail \\
\ifthenelse{\equal{\hmwkCollaborators}{}}{}{Collaborators: \hmwkCollaborators\\}
Due: \hmwkDueDate\\
\end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Part 1: Microscope Characterization}

\subsection*{B.1 Image Data}

All of our image data is read into a vector of structs, with consistent field naming. This allows us to write generic functions that can operate on any set of images we pass to it, and gives us a grouping with which to store all results bundled together.


\subsection*{B.2 Characterizing fluorescence image background noise}

To compute noise statistics, we first crop out a region of the image containing noise. To do so, a region in each image that contained no features was manually found, and then that region was stored into our script for repeatability. Each image is then cropped using this region, and the mean and variance is calculated over the cropped region.

To determine the distribution of the data, the noise samples were plotted in a histogram and inspected visually. Upon observation, it was found that the data appears to follow a Gaussian distribution, shown in Figure \ref{fig:noise_dist_background}.

Once we had a belief that our noise was normally distributed, we used the Kolmogorov-Smirnov test (implemented in MATLAB as \verb|kstest|) to verify this. This test works by comparing the analytic cumulative distribution function of a distribution to the actually observed CDF for the data. The difference in the distribution gives a confidence interval on how likely the data is to come from a given distribution, and this test confirms with with 95\% confidence that at least 140 of our 150 cropped noise images are drawn from a normal distribution.

To analyze the image sequence over time, we then generated plots showing the mean and variance of the noise over time for the image sequence. We found that both the mean and variance of the noise intensity decreased over time, shown in Figure \ref{fig:noise_mean_var_time}.

To analyze the spatial dependency of the noise, we plotted the mean of noise over columns in one plot, and rows in another (Figure \ref{fig:noise_intensity_space}). We found that the intensity was highest for our noise field in the top left, and lowest in the bottom right. The noise displays a rough linear decay across the image in both the $x$ and $y$ directions.

% TODO: FIGURES

\begin{figure}[b]
\begin{minipage}[b]{0.45\linewidth}
\centering
\includegraphics[width=\textwidth]{figures/noise_distribution_background.png}
\caption{Noise distribution in background}
\label{fig:noise_dist_background}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[b]{0.45\linewidth}
\centering
\includegraphics[width=\textwidth]{figures/noise_mean_variance_over_time.png}
\caption{Noise Mean \& Variance over time}
\label{fig:noise_mean_var_time}
\end{minipage}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.45\linewidth]{figures/noise_intensity_over_space.png}
\caption{Average Noise Intensity over Space}
\label{fig:noise_intensity_space}
\end{figure}


\subsection*{B.3 Characterizing illumination uniformity}

The method we used to characterize uniformity of illumination was essentially to compare the extrema of the image with how a close-to-ideal uniform image should be. The image is first filtered with a large low-pass Gaussian kernel to smooth out the image; this helps eliminate many extreme outliers that would strongly affect the results.

The global maximum and minimum are then taken from the filtered image and then the difference is found.  This difference is compared with the difference of the maximum and minimum of some background noisy image; this is because a background image is an image with close-to-ideal uniformity of illumination, so it is appropriate to compare the two differences.



\subsection*{B.4 Microscope pixel calibration}
 
Two different methods were implemented to calibrate pixel sizes in our images.

The first method is manual. The user is presented with an image, and asked to crop out a section of it along the provided calibration bars. They are then asked to report how many bars wide the section they cropped is. The crop width is then matched with the bar spacing to report the size of each pixel in microns.

The second method is automated. First, the Hough Transform of the image is taken, in the vertical direction, and edges of this transpose are found. Once these edges are found, we match the first bar to its neighbor. The distance between these neighbors is taken, and statistical outliers are removed between elements of each bar. Finally, the distance between these bars is used in tandem with the bar spacing to report the size of each pixel in microns.


\subsection*{B.5 Implementation of a directional anisotropic filter}

In order to detect lines in a certain direction, it can be useful to blur an image more strongly in directions parallel to the line than perpendicular. This can preserve detail in the salient directions while helping to disguise noise off axis. In order to do this, we have implemented a Gaussian anisotropic filter as described by Geusebroek et.\ al.\cite{geusebroek}.

Generating and filtering with 2D anisotropic kernels is simply in theory. However, it is often advantageous to separate a 2D kernel into a composition of two 1D kernels, for decreased computational complexity. This method does just that, by decomposing an anisotropic Gaussian kernel into a 1D kernel along the x-axis with STD $\sigma_x$, and another 1D kernel along the major axis of the Gaussian with STD $\sigma_\varphi$. Parameters for these kernels are derived as:

\[ a_{11} = \sigma_u^2 \cos^2 \theta + \sigma_v^2 \sin^2 \theta \]
\[ a_{12} = (\sigma_u^2 + \sigma_v^2)\cos\theta \sin\theta \]
\[ a_{22} = \sigma_v^2 \cos^2 \theta + \sigma_u^2 \sin^2 \theta \]
\[ \sigma_x = \sqrt{a_{11} - a_{12}^2/a_{22}} \]
\[ \sigma_\varphi = \sqrt{a_{22}} \]

Our kernels are then be convolved with individual rows for the x-axis filter, and then for interpolated lines at arbitrary pixels along the major axis.


\pagebreak
\section*{Part 2: Curvilinear feature detection}

\subsection*{C.1 Implementation of the Steger's algorithm}

We implemented Steger's algorithm to detect and identify pixels for being on lines and curves of a given image. Our implementation of Steger's algorithm first blurred a given image with a Gaussian kernel with the standard deviation of $\sigma = \frac{n}{\sqrt{3}}$, where $n$ is the estimated maximum line size in pixels. We used $n = 10$ pixels, found by visual estimation on the source images. The MATLAB command \texttt{fspecial} was used to create the kernel, followed by \texttt{filter2} for the actual filtering of the image.

Next, both the first and second order partial derivatives were calculated across the entire image in each dimension by taking the differences between the pixels, using the \texttt{diff} command. The resulting matrices were padded appropriately to match with the iteration through every pixel that will happen for the computational section.

Our algorithm then iterates through every pixel in the original image. For each pixel, it creates a Hessian matrix and gradient vector using the precomputed partials. From the Hessian matrix, the eigenvector with the corresponding eigenvalue of greatest magnitude was taken as the direction.

\begin{equation}
\text{direction vector} = [n_x, n_y]
\label{eq:direction}
\end{equation}

The first and second order directional derivatives were then calculated using equations \ref{eq:1_directional_derivative} and \ref{eq:2_directional_derivative}. The location of the local intensity maximum was calculated via equation \ref{eq:local_intensity_max}, then tested if its absolute value was less than $\frac{1}{2}$; if it was, then the pixel was marked as a center line point.

\begin{equation}
r' = [n_x,n_y][f_x,f_y]^T
\label{eq:1_directional_derivative}
\end{equation}
\begin{equation}
r'' = [n_x,n_y]H[n_x,n_y]^T
\label{eq:2_directional_derivative}
\end{equation}
\begin{equation}
x^* = -\frac{r'}{r''}
\label{eq:local_intensity_max}
\end{equation}

\begin{figure}[h]
\begin{minipage}[b]{0.3\linewidth}
\centering
\includegraphics[width=\textwidth]{figures/line_detection_1.png}
\caption{Line Detect (Image 1)}
\label{fig:line_detect_1}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[b]{0.3\linewidth}
\centering
\includegraphics[width=\textwidth]{figures/line_detection_2.png}
\caption{Line Detect (Image 2)}
\label{fig:line_detect_2}
\end{minipage}
\begin{minipage}[b]{0.3\linewidth}
\centering
\includegraphics[width=\textwidth]{figures/line_detection_3.png}
\caption{Line Detect (Image 3)}
\label{fig:line_detect_3}
\end{minipage}
\end{figure}


\subsection*{C.2 Implementation of the pixel inking operation}



\pagebreak
\begin{thebibliography}{9}
\fontsize{10pt}{12pt}\selectfont
\raggedright

    \bibitem{steger}
        C. Steger, An unbiased detector of curvilinear structures, 
        \emph{IEEE Trans. Pattern Analysis and Machine Intelligence},
        vol. 20, pp. 113-125, 1998.

    \bibitem{geusebroek}
        J. M. Geusebroek, A. W. M. Smeulders, and J. van de Weijer, 
        \ul{Fast anisotropic Gaussian filtering},
        \emph{IEEE Trans. Image Processing}, vol. 12, no. 8, pp. 938-943, 2003.


\end{thebibliography}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
