\documentclass{article}

\usepackage{amsmath,amsfonts,amsthm,amssymb}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{lastpage}
\usepackage{graphicx}
\usepackage{supertabular}
\usepackage{multirow}
\usepackage{ifthen}
\usepackage{enumerate}
\usepackage{subcaption}
\usepackage[hidelinks]{hyperref}
\usepackage{soul}
\usepackage[mediumspace,mediumqspace,squaren]{SIunits}

% In case you need to adjust margins:
\topmargin=-0.5in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

% Homework Specific Information
\newcommand{\hmwkTitle}{Project Report 4}
\newcommand{\hmwkDueDate}{May 5th, 2014}
\newcommand{\hmwkClass}{42-731}
\newcommand{\hmwkAuthor}{Alex Sun Yoo, Michael Nye, Ozan Iskilibli}
\newcommand{\hmwkEmail}{ayoo, mnye, oiskilib}
\newcommand{\hmwkCollaborators}{}
\newcommand{\bigspace}{\vspace{.25in}}

% Tools for formatting questions
\newcommand{\question}[1] {\vspace{.25in} \hrule\vspace{0.5em}
\noindent{\bf #1} \vspace{0.5em}
\hrule \vspace{.10in}}
\renewcommand{\part}[1] {\vspace{.10in} {\bf (#1)}}

% Setup the header and footer
\pagestyle{fancyplain}
\lhead{\fancyplain{}{\hmwkAuthor \\ \hmwkEmail}}
\chead{\fancyplain{}{\textbf{\hmwkTitle}}}
\rhead{\fancyplain{}{\hmwkClass \\ Due:\ \hmwkDueDate}}
\lfoot{}
\cfoot{}
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}}
\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

% Format paragraphs to have spacing instead of indents
\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}

% This is used to trace down (pin point) problems
% in latexing a document:
%\tracingall

\renewcommand{\arraystretch}{1.5}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\thispagestyle{plain}
\begin{center}
{\Large \hmwkClass\ \hmwkTitle} \\
\hmwkAuthor \\
\hmwkEmail \\
\ifthenelse{\equal{\hmwkCollaborators}{}}{}{Collaborators: \hmwkCollaborators\\}
Due: \hmwkDueDate\\
\end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Part 1: Image segmentation using MAT-ITK}

\subsection*{B.1 MAT-ITK and image data}

Our images and their corresponding segmentations are stored in a vector of structs, allowing us to keep all information bundled together.

The MAT\_ITK library is included in our code as a MEX file. We elected to write wrapper functions to convert between our data structs and the format required by the library. This simplifies repeatedly calling the library, as the data format for the library is strange and poorly documented.

It was difficult to find documentation on what function parameters actually were. Fortunately, I was able to find external documentation on how to use some functions\cite{designest}.


\subsection*{B.2.1 Segmentation of static images}

For this assignment, our two assigned algorithms were Connected Threshold Segmentation (CST), and Laplacian Level Set Segmentation (LLSS).

\subsubsection*{Connected Threshold Segmentation}
To perform CST, we must pass in two parameters. The first is a pair of thresholds corresponding to the minimum and maximum values in our segments. The second is a set of seed coordinates, one for each blob we want to segment. For our two test images, these were both derived by manually inspecting the image. See Figure {\bf FIGNUMHERE} for results.

\subsubsection*{Laplacian Level Set Segmentation}
To perform LLSS, several parameters were required. The last three had suggested values in the documentation, and we found that the suggested values produced quite good segmentation results. Second, we had to pass in a starting segmentation and a parameter that informs the algorithm what is a segment in the starting segmentation.

LLSS requires an initial segmentation as a seed that it then uses to refine to a better boundary. To seed the algorithm, we used a naive thresholding segment on the image, derived manually by inspecting the image. Finally, the algorithm required a propagation scaling constant. This was manually tuned, and found to produce optimal results between 0 and 1.

% TODO: CST/LLSS figures


\subsection*{B.2.2 Segmentation of images series}

The image series was segmented using the same functions as the in B.2.1. Thresholds were again manually determined by inspecting representative images in the series. The CST was instead seeded using local maxima in the image. See {\bf FIGNUMHERE} for results.

% TODO: results figure


\subsection*{B.2.3 Theoretical background}

\subsubsection*{Connected Threshold Segmentation}
Connected Threshold Segmentation is a very simple algorithm. It begins with one or more starting coordinates, called the {\bf seeds}. For each seed location, we search the neighborhood around the point. The most common neighborhood is simply the eight adjacent pixels. For each grayscale pixel, we compare against two thresholds, $T_L$ and $T_H$. If the pixel intensity $p_i$ is in the range $T_L \leq p_i \leq T_H$, then this pixel is added to the segmentation. Finally, for each pixel found this way, iteratively continue expanding the segmentation. The algorithm terminates when no new pixels are found in the next iteration step.\cite{svi}

This algorithm is incredibly simple, and thus easy both to implement and tune the parameters for. In the case of our clean test images, it actually produces quite clean results with minimal effort. However, it requires that the user feeds the algorithm with knowledge for each image that describes the segments, meaning it is hard to fully automate.

\subsubsection*{Laplacian Level Set Segmentation}

Level set segmentation derives form a mathematical property called the level set. A level set is simply the set of all points for a function $f$ where $f(x) = c$, where $c$ is some constant. Level set algorithms define the ``interface'' as the dividing line between a segment and everything else, and seeks to define a function $\varphi(\mathbf{x},t)$ such that $\varphi$ is strictly positive (or negative) when inside a segment, strictly negative (or positive) outside a segment, and strictly $0$ on the dividing line. Thus, the segmentation can be found by finding the level set $\Gamma(t)$ that causes $\varphi$ to {\emph vanish} (that is, to go to zero).

To perform optimization, a velocity field is defined $\mathbf{v}(\mathbf{x},t)$. Thus, we evolve the equation\cite{osher}:

\[\frac{\delta\varphi}{\delta t} + \mathbf{v} \nabla\varphi = 0 \]

Using Lagrangian methods, this is done by evolving particle positions to track the interface. Starting at an initial position $\mathbf{x_0}$, with an initial volume of segmentation $v_0$, on the initial boundary, we update our state on the next $p$th step as follows\cite{hieber}:

\[\frac{D\varphi_p}{Dt} = 0 \]
\[\frac{Dv}{Dt} = \left< \nabla\mathbf{v}\right>_p v_p \]
\[\frac{D\mathbf{x}_p}{Dt} = \mathbf{v}_p \]

By iterating this for each point on our segmentation boundary, we will eventually converge on our final boundary. The advantage of using particle based adjustment of these boundaries is that they allow for fast and relatively accurate approximations of our actual surface we are traversing. Their primary disadvantage is that sometimes, points can get caught in ``snags'' along their path that causes them to converge to suboptimal locations. This is usually a result of accumulated errors in the approximation of our distance function, and it can be fixed reinitializing our sets by recomputing initial values at our current position and continuing\cite{hieber}.

LLSS as an algorithm is very good at adjusting existing edges that are near actual segmentations. However, because the gradients tend to be small far from edges, it is not as good at guessing initial boundaries and crossing wide spaces\cite{osher}. Thus, given very rough or noisy segmentations by other methods, LLSS makes an excellent second pass to produce clean segmentations.

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{figures/changme.pdf}
\caption{CHANGEME figure as a placeholder}
\label{fig:noise_dist_background}
\end{figure}


\clearpage
\section*{Part 2: Image segmentation using graph-cut and active contour}

\subsection*{C.1.1 Graph cut based image segmentation}

\subsection*{C.1.2 Active contour based image segmentation}
Active contours, or \emph{snakes}, are quite useful for finding object boundaries in an image. The initial contours are evolving due to the internal forces, that are elasticity forces, holding the curve together, and bending forces, controlling stiffness of the curve, and external forces, that are potential forces due to image gradients and pressure forces. Reference \cite{gvf} indicates that there are 2 main challenges in active contour based image segmentation:
\begin{itemize}
\item Initial contours should start in the vicinity of the true region boundaries
\item It is generally hard to penetrate into concave regions.
\end{itemize}
In this project, Gradient Vector Flow Segmentation (GVF) \cite{gvf} and Distance Regularized Level Set Evolution (DRLSE) Segmentation \cite{drlse} are examined and applied to the current sample images, in order to exemplify the functionality and challenges in active contour based image segmentation. In the following, the results for the implementation of each algorithm will be given, however, the technical background will be discussed in section C.1.3.



\subsubsection*{Gradient Vector Flow Segmentation}
The GVF segmentation has several user inputs from the user. First of all, it needs the initial snake entered by the user. The snake deformation starts from this initial curve. Second, it needs some weighting parameters to evaluate the deformed curve. These parameters are, $\mu$, a parameter that weights the GVF strength, $\alpha$, that weighs the tension of the curve and $\beta$ that controls the rigidity of the snake.


\subsubsection*{Distance Regularized Level Set Evolution Segmentation}


\subsection*{C.1.3 Theoretical background}

\subsubsection*{Gradient Vector Flow Segmentation}


GVF method is proposed in \cite{gvf} and it implements a parametric active contour segmentation that addresses above explained challenges by building a force balance equation where the external forces are represented by the GVF function, derived from the image itself. When a couple of exact partial differential equations are solved, the resulting GVF is utilized to build a snake that minimizes a cost function (energy function) and practically, it can penetrate into concave regions easily and it is not sensitive to the initialization any more. 

The GVF segmentation is implemented in several steps. Although the mathematical representation looks complex, the notion of the algorithm is reasonably simple and summarized in the following steps:
\begin{enumerate}
\item Detection of the edges in the images and storing them in edge map.
\item Computation of the GVF of the edge map, that is a vector field pointing towards edges.
\item Formation of the initial snake, as a user input or a pre-defined curve.
\item Deformation of the snake, such that the internal and external forces are balanced at a given time.
\item Iteration of the previous step for a given number of times.
\end{enumerate}

The edge detection in step 1 is implemented by some preprocessing effort for background suppression and ``Canny Edge Detection'' using built-in functions in MATLAB and in particular the `edge' function. For the step 2, the GVF is evaluated as a vector $\mathbf{v}=(u(x,y),\, v(x,y)$, that minimizes an energy function, $\varepsilon$:
\begin{align*}
\varepsilon = \int \int \mu \cdot (u_x^2 +u_y^2+v_x^2+v_y^2)+|\nabla f|\cdot |\mathbf{v}-\nabla f|^2 \cdot dxdy
\end{align*}
where the $\mu$ is a constant regulating the noise level as well as the trade-off between the first term that smoothes the result and the second term that is pointing towards the edges. If the image is a smooth surface, then the 2$^{nd}$ term in the integral would vanish, because the gradient around the edges would be about zero in magnitude and then the first part of the integral would be minimal, resulting in a smooth GVF. On the other hand, if the image surface is harsh, e.g. it is just high frequency noise, then the second term is non-zero and actually large in magnitude, making the first term in the integral counter-balance, making the gradient magnitudes larger. The regulation term $\mu$ could be set to scale the GVF magnitude.

The 3$^{rd}$ step is basically a user entry of the initial snake whether a circular or a rectangular region. The 4$^{th}$ step is implemented as:
\begin{align*}
\mathbf{x}_t(s,t) = \alpha \mathbf{x}'' - \beta \mathbf{x}'''' + \mathbf{v}
\end{align*}
where the resulting parametric curve $\mathbf{x}(s,t)$ is the GVF snake at a time $t$. After a sufficient amount of time, this curve supposedly converges to feature boundaries in the image.

GVF is quite powerful, especially because of the fact that the initial guess could be inside or outside or even partly overlapping with the targeted segmentation. The GVF snake can expand and shrink in every direction. One drawback is that it relies on high quality edge detection. If the smoothing filter in Canny edge detection is not strong enough (i.e. small $\sigma$ and consequently small span) then some residual edges are left in target regions. In that case, the snake stops when it reaches to these residual edges. Therefore, the implemented filtering functionality is tailored for our images.

\subsubsection*{Distance Regularized Level Set Evolution Segmentation}



\clearpage
\begin{thebibliography}{9}
\fontsize{10pt}{12pt}\selectfont
\raggedright

    \bibitem{designest}
        ``MATITK: Additional documentation''.
        \emph{designest}.
        \url{http://designest.de/2009/11/matitk-additional-documentation/}.

    \bibitem{hieber}
        Hieber, Simone E., and Koumoutsakos, Petros.
        ``A Lagrangian particle level set method''.
        Institute of Computational Science, ETH Zürich.
        \emph{Journal of Computational Physics}, 2005, 342-367.

    \bibitem{osher}
        Osher, Stanley, and Nikos Paragios, eds. 
        \emph{Geometric level set methods in imaging, vision, and graphics}.
        Springer, 2003.

    \bibitem{svi}
        ``Seed and threshold Segmentation''.
        \emph{Scientific Volume Imaging}.
        \url{http://www.svi.nl/SeedAndThreshold}.

    \bibitem{gvf}
        C. Xu and J. L. Prince, ``Gradient Vector Flow: A New External Force for Snakes''.
        \emph{Proc. IEEE Conf. on Comp. Vis. Patt. Recog. (CVPR)}, 
        Los Alamitos: Comp. Soc. Press, pp. 66-71, June 1997.

    \bibitem{drlse}
        C. Li, C. Xu, C. Gui, and M. D. Fox, 
        ``Distance Regularized Level Set Evolution and its Application to Image Segmentation''.
        \emph{IEEE Trans. Image Processing}, 
        vol. 19 (12), 2010.
        
        
\end{thebibliography}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
